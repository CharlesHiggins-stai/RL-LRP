{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post training with hybrid loss evaluation against a sanity check model\n",
    "The objective of this notebook is to demonstrate that one can optimise a network via training with a hybrid loss. \n",
    "The training losses (available on wandb at this link: ) demonstrate minimal performance improvement at asymptotic convergence than a sanity-check alternative. \n",
    "The objective here is to evaluate the quality of explanations which have been generated by these models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The following functions contain the bulk of the specific helper functions necessary to evaluate the performance and explanation of VGG16 vs VGG19. \n",
    "Generic helper functions have been moved to the utils folder for use in other notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from baselines.trainVggBaselineForCIFAR10 import vgg\n",
    "from experiments import WrapperNet, perform_lrp_plain, evaluate_performance, evaluate_explanations\n",
    "from internal_utils import get_vgg16, get_vgg19, get_pretrained_model, get_CIFAR10_dataloader, preprocess_images, condense_to_heatmap, blur_image_batch, add_random_noise_batch, get_CIFAR_10_dataloader_without_normalization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRUNCATE = 25\n",
    "print(f\"WARNING: TRUNCATING THE DATASET TO {TRUNCATE} --- THIS WILL ALSO BE TRUNCATED IN THE FUNCTIONS INCLUDED IN THE experiments/run_evaluation.py FILE\")\n",
    "print(f\"TO RUN OVER THE ENTIRE DATASET, UNCOMMENT THE RELEVANT LINES IN THE FUNCTIONS (SEARCH FOR THE STRING 'TRUNCATE')\")\n",
    "\n",
    "\n",
    "def plot_comparative_figure(df, method_0, method_1, data_type=\"Train\", big_small_filter=False):\n",
    "    \"\"\"\n",
    "    Plot a comparative figure of the results between the two models.\n",
    "    \"\"\"\n",
    "    figs_per_row = [\"distance_noise_small\", \"distance_noise_large\", \"distance_blur_small\", \"distance_blur_large\"]\n",
    "\n",
    "    # Create a single row figure with two boxplots per column\n",
    "    fig, axs = plt.subplots(1, len(figs_per_row), figsize=(20, 5), sharey=True)\n",
    "\n",
    "    for j, fig_type in enumerate(figs_per_row):\n",
    "        # Filter data for method_0\n",
    "        if big_small_filter:\n",
    "            if \"small\" in fig_type:\n",
    "                df_method_0 = df[df[f\"{method_0}_{fig_type}_class_change\"] == False]\n",
    "            else:\n",
    "                df_method_0 = df[df[f\"{method_0}_{fig_type}_class_change\"] == True]\n",
    "        else:\n",
    "            df_method_0 = df\n",
    "        # Filter data for method_1\n",
    "        if big_small_filter:\n",
    "            if \"small\" in fig_type:\n",
    "                df_method_1 = df[df[f\"{method_1}_{fig_type}_class_change\"] == False]\n",
    "            else:\n",
    "                df_method_1 = df[df[f\"{method_1}_{fig_type}_class_change\"] == True]\n",
    "        else:\n",
    "            df_method_1 = df\n",
    "        # Combine the data for boxplot using a hue for methods\n",
    "        combined_df = pd.DataFrame({\n",
    "            'Value': pd.concat([df_method_0[f\"{method_0}_{fig_type}\"], df_method_1[f\"{method_1}_{fig_type}\"]]),\n",
    "            'Method': [method_0] * len(df_method_0) + [method_1] * len(df_method_1)\n",
    "        })\n",
    "\n",
    "        # Create boxplot\n",
    "        sns.boxplot(x='Method', y='Value', hue= 'Method', data=combined_df, ax=axs[j])\n",
    "        axs[j].set_title(f\"{fig_type}\".replace(\"_\", \" \"))\n",
    "    fig.suptitle(f\"Comparative Analysis of {method_0} and {method_1} on {data_type} Data\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualise_panel_image(image, label, model, kernel_size_min=1, kernel_size_max=7, noise_level_min=0.05, noise_level_max=0.3, method=perform_lrp_plain, fig_label=\"LRP\"):\n",
    "    \"\"\"Visualise the panel of images for the model.\"\"\"\n",
    "    # Assume the image tensor is already in batch format, if not, unsqueeze it\n",
    "    if image.dim() == 3:\n",
    "        image = image.unsqueeze(0)\n",
    "    \n",
    "    original_image = image\n",
    "    # treated images\n",
    "    blurred_small = blur_image_batch(image, kernel_size_min)\n",
    "    blurred_large = blur_image_batch(image, kernel_size_max)\n",
    "    noisy_small = add_random_noise_batch(image, noise_level_min)\n",
    "    noisy_large = add_random_noise_batch(image, noise_level_max)\n",
    "    \n",
    "    # model outputs\n",
    "    original_heatmap = condense_to_heatmap(method(preprocess_images(image), label, model, return_output=False)).detach()\n",
    "    blurred_small_heatmap = condense_to_heatmap(method(preprocess_images(blurred_small), label, model, return_output=False)).detach()\n",
    "    blurred_large_heatmap = condense_to_heatmap(method(preprocess_images(blurred_large),label,  model, return_output=False)).detach()\n",
    "    noisy_small_heatmap = condense_to_heatmap( method(preprocess_images(noisy_small), label, model, return_output=False)).detach()\n",
    "    noisy_large_heatmap = condense_to_heatmap(method(preprocess_images(noisy_large), label, model, return_output=False)).detach()\n",
    "    \n",
    "    # Display images\n",
    "    fig, ax = plt.subplots(2, 5, figsize=(15, 5))\n",
    "    ax[0][0].imshow(original_image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0][0].set_title('Original Image')\n",
    "    ax[0][1].imshow(blurred_small.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0][1].set_title('Small Blurred Image')\n",
    "    ax[0][2].imshow(blurred_large.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0][2].set_title('Large Blurred Image')\n",
    "    ax[0][3].imshow(noisy_small.squeeze().detach().permute(1, 2, 0).cpu().numpy())  # Example visualization\n",
    "    ax[0][3].set_title('Small Noisy Image')\n",
    "    ax[0][4].imshow(noisy_large.squeeze().detach().permute(1, 2, 0).cpu().numpy())  # Example visualization\n",
    "    ax[0][4].set_title('Large Noisy Image')\n",
    "    \n",
    "    ax[1][0].imshow(original_heatmap.squeeze(0), cmap='seismic')\n",
    "    ax[1][0].set_title('Original Heatmap')\n",
    "    ax[1][1].imshow(blurred_small_heatmap.squeeze(0), cmap='seismic')\n",
    "    ax[1][1].set_title('Small Blurred Heatmap')\n",
    "    ax[1][2].imshow(blurred_large_heatmap.squeeze(0), cmap='seismic')\n",
    "    ax[1][2].set_title('Large Blurred Heatmap')\n",
    "    ax[1][3].imshow(noisy_small_heatmap.squeeze(0), cmap ='seismic')  # Example visualization\n",
    "    ax[1][3].set_title('Small Noisy Heatmap')\n",
    "    ax[1][4].imshow(noisy_large_heatmap.squeeze(0), cmap ='seismic')  # Example visualization\n",
    "    ax[1][4].set_title('Large Noisy Heatmap')\n",
    "    fig.suptitle(f\"{fig_label}\")\n",
    "    \n",
    "    for i in ax:\n",
    "        for j in i:\n",
    "            j.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training evaluation\n",
    "Here, we evaluate the performance of the models on the test and train data, and then evaluate the quality of explanations over the same datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the models\n",
    "hybrid_model = get_pretrained_model(\"/Users/charleshiggins/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/model_files/checkpoint_299_2024-08-06_02-23-55_default.tar\", vgg.vgg11)\n",
    "baseline_model  = get_pretrained_model(\"/Users/charleshiggins/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/model_files/checkpoint_299_2024-08-06_11-16-09_sanity_check.tar\", vgg.vgg11)\n",
    "\n",
    "# Load test and train data to run evaluation over\n",
    "train_data, test_data = get_CIFAR_10_dataloader_without_normalization(train=True, batch_size=8, num_workers=4, pin_memory=True), get_CIFAR_10_dataloader_without_normalization(train=False, batch_size=8, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Generate some sample images of the data\n",
    "NUM_IMAGES = 4\n",
    "images, labels = next(iter(train_data))\n",
    "image_batch, label_batch = images[:4], labels[:4]\n",
    "for image, label in zip(image_batch, label_batch):\n",
    "    print(f\"Label type: {label.shape}\")\n",
    "    print(f\"Image Shape: {image.shape}\")\n",
    "    visualise_panel_image(image, label.unsqueeze(0), WrapperNet(hybrid_model, hybrid_loss=True), method=perform_lrp_plain, fig_label=\"LRP HYBRID MODEL\")\n",
    "    visualise_panel_image(image, label.unsqueeze(0), WrapperNet(baseline_model, hybrid_loss=True), method=perform_lrp_plain, fig_label=\"LRP BASELINE MODEL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyse performance over train and test set on the two models\n",
    "hybrid_results_train, hybrid_results_test = evaluate_performance(hybrid_model, train_data, test_data, convert_to_imagenet_labels=False)\n",
    "baseline_results_train, baseline_results_test  = evaluate_performance(baseline_model, train_data, test_data, convert_to_imagenet_labels=False)\n",
    "\n",
    "# visualise results from the initial dataframes\n",
    "hybrid_results_train['model'] = 'HYBRID'\n",
    "hybrid_results_test['model'] = 'HYBRID'\n",
    "baseline_results_train['model'] = 'BASELINE'\n",
    "baseline_results_test['model'] = 'BASELINE'\n",
    "\n",
    "# Concatenate dataframes\n",
    "combined_df_train = pd.concat([hybrid_results_train, baseline_results_train])\n",
    "combined_df_test = pd.concat([hybrid_results_test, baseline_results_test])\n",
    "\n",
    "# Melt the dataframe to long format for seaborn\n",
    "melted_df_train = combined_df_train.melt(id_vars=['model'], var_name='metric', value_name='value')\n",
    "melted_df_test = combined_df_test.melt(id_vars=['model'], var_name='metric', value_name='value')\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='metric', y='value', hue='model', data=melted_df_train)\n",
    "plt.title('Model Performance Comparison (Train Set)')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(title='Model (Train)')\n",
    "plt.show()\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='metric', y='value', hue='model', data=melted_df_test)\n",
    "plt.title('Model Performance Comparison (Test Set)')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(title='Model (Test)')\n",
    "plt.show()\n",
    "\n",
    "# To evaluate the explanations, we need to pass in a list of \"methods\"\n",
    "# each method is a tuple of the form (name, method, model)\n",
    "# name is a string which identifies the method -- i.e. \"VGG16\"\n",
    "# method is a function which generates a heatmap on a certain model --- i.e. perform_lrp_plain\n",
    "# model is the model which the method is applied to --- it needs to be in the heatmap form (i.e.)\n",
    "methods = [\n",
    "        (\"HYBRID\", perform_lrp_plain, WrapperNet(hybrid_model, hybrid_loss=True)),\n",
    "        (\"BASELINE\", perform_lrp_plain, WrapperNet(baseline_model, hybrid_loss=True))\n",
    "    ]\n",
    "# now evaluate explanations\n",
    "print(\"WARNING: EVAULUATING EXPLANATIONS IS TOO COMPUTATIONALLY INTENSE FOR A NOTEBOOK. WE SUGGEST RUNNING THIS IN A SCRIPT, AND LOADING THE RESULTS FROM .csv FILES FOR ANALYSIS.\")\n",
    "# df_train, df_test = evaluate_explanations(train_data, test_data, methods, save_results = True, convert_to_imagenet_labels=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/charleshiggins/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP\"\n",
    "df_train = pd.read_csv(f\"{ROOT_DIR}/explanation_evaluation_CIFAR10__train_results.csv\")\n",
    "df_test = pd.read_csv(f\"{ROOT_DIR}/explanation_evaluation_CIFAR10__test_results.csv\")\n",
    "plot_comparative_figure(df_test, \"HYBRID\", \"BASELINE\", \"Test\")\n",
    "# plot_comparative_figure(df_train, \"HYBRID\", \"BASELINE\", \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"hybrid-baseline-CIFAR10_train_results.csv\")\n",
    "# df_test.to_csv(\"hybrid-baseline-CIFAR10_test_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_polarised = pd.read_csv(f\"{ROOT_DIR}/explanation_evaluation_CIFAR10_polarised_results_train_results.csv\")\n",
    "df_test_polarised = pd.read_csv(f\"{ROOT_DIR}/explanation_evaluation_CIFAR10_polarised_results_test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_comparative_figure(df_train_polarised, \"HYBRID\", \"BASELINE\", \"Polarised Train\")\n",
    "plot_comparative_figure(df_test_polarised, \"HYBRID\", \"BASELINE\", \"Polarised Test\", big_small_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
