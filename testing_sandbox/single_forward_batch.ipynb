{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from experiments import perform_gradcam, perform_lrp_captum\n",
    "from internal_utils import preprocess_images, condense_to_heatmap, blur_image_batch, add_random_noise_batch, get_data_imagenette, get_teacher_model, get_CIFAR10_dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import WrapperNet, WrapperNetContrastive\n",
    "import torch\n",
    "from internal_utils import update_dictionary_patch\n",
    "from baselines.trainVggBaselineForCIFAR10.vgg import vgg11\n",
    "\n",
    "def get_teacher_model(teacher_checkpoint_path):\n",
    "    checkpoint = torch.load(teacher_checkpoint_path)\n",
    "    # assume teacher model is vgg11 for now\n",
    "    teacher = vgg11()\n",
    "    try: \n",
    "        checkpoint = update_dictionary_patch(checkpoint)\n",
    "        teacher.load_state_dict(checkpoint['new_state_dict'])\n",
    "    except:\n",
    "        print('Incorrect patch specified')\n",
    "    return teacher\n",
    "# data = get_CIFAR10_dataloader(train=True, batch_size=8)\n",
    "# data_test = get_CIFAR10_dataloader(train=False, batch_size=8)\n",
    "# input_images, labels = next(iter(data))\n",
    "# teacher_model = WrapperNet(get_teacher_model(\"/home/charleshiggins/RL-LRP/baselines/trainVggBaselineForCIFAR10/save_vgg11/checkpoint_299.tar\"), hybrid_loss=True)\n",
    "# # define params\n",
    "# learner_model = WrapperNet(vgg11(), hybrid_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from experiments import perform_lrp_plain\n",
    "# input_images, labels = next(iter(data))\n",
    "# sample_image, sample_label = input_images[0], labels[0]\n",
    "# visualise_panel_image(sample_image.unsqueeze(0), teacher_model, 3, 15, 0.1, 0.5, perform_lrp_plain, sample_label.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise_panel_image(sample_image.unsqueeze(0), learner_model, 3, 15, 0.1, 0.5, perform_lrp_plain, sample_label.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp_images = preprocess_images(input_images)\n",
    "# print(f\"The target tensor should be: {labels}\")\n",
    "# output, heatmap = learner_model(pp_images)\n",
    "# output_target, heatmap_target = teacher_model(pp_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class CosineDistanceLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Flatten the images: shape from [b, 1, 28, 28] to [b, 784]\n",
    "        input1_flat = input1.view(input1.size(0), -1)\n",
    "        input2_flat = input2.view(input2.size(0), -1)\n",
    "        \n",
    "        # Compute cosine similarity, then convert to cosine distance\n",
    "        cosine_sim = F.cosine_similarity(input1_flat, input2_flat)\n",
    "        cosine_dist = 1 - cosine_sim\n",
    "        \n",
    "        # Calculate the mean of the cosine distances\n",
    "        loss = cosine_dist.mean()\n",
    "        # loss = F.mse_loss(input1_flat, input2_flat)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "# Define SSIM loss (we'll minimize 1 - SSIM)\n",
    "class SSIMLoss(torch.nn.Module):\n",
    "    def __init__(self, data_range=1.0, size_average=True, channel=3):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.ssim_module = SSIM(data_range=data_range, size_average=size_average, channel=channel)\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        ssim_value = self.ssim_module(img1, img2)\n",
    "        return 1 - ssim_value\n",
    "    \n",
    "class Tracker:\n",
    "    # small tracker class to compute moving averages\n",
    "    def __init__(self):\n",
    "        self.ce_losses = []\n",
    "        self.ssim_losses = []\n",
    "        self.accs = []\n",
    "    \n",
    "    def update(self, ce_loss, ssim_loss, acc):\n",
    "        # add values to the tracker\n",
    "        self.ce_losses.append(ce_loss)\n",
    "        self.ssim_losses.append(ssim_loss)\n",
    "        self.accs.append(acc)\n",
    "    \n",
    "    \n",
    "    def get_avg(self):\n",
    "        # get the average of the last 10 values\n",
    "        if len(self.ce_losses) <= 10:\n",
    "            return np.mean(self.ce_losses), np.mean(self.ssim_losses), np.mean(self.accs)\n",
    "        else: \n",
    "            return np.mean(self.ce_losses[-10:]), np.mean(self.ssim_losses[-10:]), np.mean(self.accs[-10:])\n",
    "    \n",
    "    def get_results(self):\n",
    "        results = {\n",
    "            \"CrossEntropyLoss\": np.array(self.ce_losses),\n",
    "            \"SSIMLoss\": np.array(self.ssim_losses),\n",
    "            \"Accuracy\": np.array(self.accs)\n",
    "        }\n",
    "        return results\n",
    "\n",
    "            \n",
    "    \n",
    "def remove_grad_for_all_but_last_layer(learner_model, optimizer, scheduler, verbose=False):\n",
    "    for name, module in learner_model.model.named_modules():\n",
    "        if not isinstance(module, nn.Sequential) \\\n",
    "        and not isinstance(module, WrapperNet) \\\n",
    "        and not len(list(module.children())) > 0 \\\n",
    "            and type(module) not in [nn.ReLU, nn.MaxPool2d, nn.AdaptiveAvgPool2d, nn.LogSoftmax, nn.Dropout]:\n",
    "            if verbose:\n",
    "                print(name)\n",
    "                print(module)\n",
    "                print(\"####################### \\n\")\n",
    "            if \"classifier.6\" not in name:\n",
    "                print(f\"removing grad from: {name}\")\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "            else:\n",
    "                print(f\"Grad will continue for {name}\")\n",
    "    optimizer = torch.optim.SGD(learner_model.parameters(), lr=0.5, momentum=0.9, weight_decay=5e-4)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "\n",
    "    return learner_model, optimizer, scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import numpy as np\n",
    "# get the dataset\n",
    "data = get_CIFAR10_dataloader(train=True, batch_size=8)\n",
    "data_test = get_CIFAR10_dataloader(train=False, batch_size=8)\n",
    "# load data and preprocess\n",
    "input_images, labels = next(iter(data))\n",
    "pp_images = preprocess_images(input_images)\n",
    "# break to avoiding having to reload the data everytime\n",
    "\n",
    "def train_baseline(pp_images, labels, teacher_heatmap, optimizer, scheduler, epochs=100):\n",
    "    # we pass in the optimizer and scheduler to allow for the learning rate to be updated and changed\n",
    "    # to keep things the same\n",
    "    learner_model = WrapperNet(vgg11(), hybrid_loss=True)\n",
    "    ssim_loss = SSIMLoss()\n",
    "    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    tracker = Tracker()\n",
    "    for i in range(epochs):\n",
    "        model_out, model_heatmap = learner_model(pp_images)\n",
    "        # loss for measurement, but not for backprop\n",
    "        img_loss = ssim_loss(model_heatmap, teacher_heatmap)\n",
    "        # now training loop starts\n",
    "        optimizer.zero_grad()\n",
    "        acc_loss = cross_entropy_loss(torch.nn.functional.log_softmax(model_out, dim=1), labels)\n",
    "        acc_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(learner_model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # store results\n",
    "        correct = model_out.argmax(dim=1).eq(labels).sum().item()\n",
    "        correct_pct = 100 * correct/labels.shape[0] \n",
    "        tracker.update(ce_loss = acc_loss.item(), ssim_loss = img_loss.item(), acc = correct_pct)\n",
    "        mov_ce, mov_ssim, mov_acc = tracker.get_avg()\n",
    "        print(f\"iteration: {i} \\t accuracy: {correct_pct:.4f} ({mov_acc:.4f})\\t image loss: {img_loss.float():.4f} ({mov_ssim:.4f})\\t cross entropy loss: {acc_loss.float():.4f} ({mov_ce:.4f}) \\t learning rate: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "        # clean up hooks\n",
    "        learner_model.remove_hooks()\n",
    "        learner_model.reapply_hooks()\n",
    "    results = tracker.get_results()\n",
    "    print(\"#\" * 10)\n",
    "    print(\"#\" * 10)\n",
    "    print(\"Baseline training completed\")\n",
    "    print(\"#\" * 10)\n",
    "    print(\"#\" * 10)\n",
    "    return results, learner_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code blocks demonstrate three facets of the differential LRP implementation. All provide evidence of the efficacy of direct explanation optimization. \n",
    "The idea belying this is to use the heatmap training loss to directly optimize the parameters of the underlying learner network to pay attention to specific features. \n",
    "\n",
    "This notebook explores and demonstrates three benefits and facets of training to optimise explanations. \n",
    "- We demonstrate that after considerable \"pre-training\" post-training achieves a high level of performance faster than simply training from scratch.  \n",
    "    - We pre-train to optimise explanations, and then train a baseline model and demonstrate convergence happens somewhat faster than without. \n",
    "- We demonstrate that features learned are more general, rather than overspecialising --- essentially demonstrating that learning with a cosine-loss avoid overfitting. \n",
    "    - We train with a hybrid/pure loss and then sharpen with CE, and then demonstrate that the validation performance is higher when specifically overtrained on a small subset of the dataset. \n",
    "- We demonstrate that explanations can be sharpened and optimised post training with minimal loss in accuracy. \n",
    "    - We train based on a solely CE loss, and then sharpen with a hybrid loss, and demonstrate the increased performance in explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "# pp_images, labels = pp_images[:3], labels[:3]\n",
    "# define losses\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "cos_loss = CosineDistanceLoss()\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "ssim_loss = SSIMLoss()\n",
    "# get clean models\n",
    "teacher_model = WrapperNet(get_teacher_model(\"/home/charleshiggins/RL-LRP/baselines/trainVggBaselineForCIFAR10/save_vgg11/checkpoint_299.tar\"), hybrid_loss=True)\n",
    "learner_model = WrapperNet(vgg11(), hybrid_loss=True)\n",
    "# define optimizers\n",
    "optimizer = torch.optim.SGD(learner_model.parameters(), lr=0.5, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "CHANGE_POINT = 100\n",
    "EPOCHS = 400\n",
    "tracker = Tracker()\n",
    "\n",
    "print(\"target labels: \", labels)\n",
    "with torch.no_grad():\n",
    "    _, teacher_heatmap = teacher_model(pp_images, labels)\n",
    "\n",
    "# make copy of scheduler and optimizer to pass into the baseline\n",
    "optimizer_copy = copy.deepcopy(optimizer)\n",
    "scheduler_copy = torch.optim.lr_scheduler.StepLR(optimizer_copy, step_size=50, gamma=0.9)\n",
    "# train a baseline for regulat performance -- this is a model trained only on cross-entropy loss\n",
    "baseline_results, baseline_model = train_baseline(pp_images, labels, teacher_heatmap, optimizer_copy, scheduler_copy, epochs=EPOCHS)\n",
    "\n",
    "############################################\n",
    "# Now we will train the model with only the SSIM loss\n",
    "############################################\n",
    "for i in range(0, CHANGE_POINT):\n",
    "    model_out, model_heatmap = learner_model(pp_images, labels)\n",
    "    # loss for measurement, but not for backprop\n",
    "    acc_loss = cross_entropy_loss(torch.nn.functional.log_softmax(model_out, dim=1), labels)\n",
    "    # now training loop starts\n",
    "    optimizer.zero_grad()\n",
    "    img_loss = ssim_loss(model_heatmap, teacher_heatmap)\n",
    "    img_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(learner_model.parameters(), 1)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    # store results\n",
    "    correct = model_out.argmax(dim=1).eq(labels).sum().item()\n",
    "    correct_pct = 100 * correct/labels.shape[0] \n",
    "    tracker.update(ce_loss = acc_loss.item(), ssim_loss = img_loss.item(), acc = correct_pct)\n",
    "    mov_ce, mov_ssim, mov_acc = tracker.get_avg()\n",
    "    print(f\"iteration: {i} \\t accuracy: {correct_pct:.4f} ({mov_acc:.4f})\\t image loss: {img_loss.float():.4f} ({mov_ssim:.4f})\\t cross entropy loss: {acc_loss.float():.4f} ({mov_ce:.4f}) \\t learning rate: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "    # clean up hooks\n",
    "    learner_model.remove_hooks()\n",
    "    learner_model.reapply_hooks()\n",
    "\n",
    "# Write logic now to update or change the model/parameters/optimizers \n",
    "    \n",
    "# training loop after change\n",
    "print(\"############\" * 4)\n",
    "print(\"## Training loop after change ##\")\n",
    "print(\"############\" * 4)\n",
    "for i in range(CHANGE_POINT, EPOCHS):\n",
    "    model_out, model_heatmap = learner_model(pp_images)\n",
    "    # loss for measurement, but not for backprop\n",
    "    img_loss = ssim_loss(model_heatmap, teacher_heatmap)\n",
    "    # now training loop starts\n",
    "    optimizer.zero_grad()\n",
    "    acc_loss = cross_entropy_loss(torch.nn.functional.log_softmax(model_out, dim=1), labels)\n",
    "    acc_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(learner_model.parameters(), 1)\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    # store results\n",
    "    correct = model_out.argmax(dim=1).eq(labels).sum().item()\n",
    "    correct_pct = 100 * correct/labels.shape[0] \n",
    "    tracker.update(ce_loss = acc_loss.item(), ssim_loss = img_loss.item(), acc = correct_pct)\n",
    "    mov_ce, mov_ssim, mov_acc = tracker.get_avg()\n",
    "    print(f\"iteration: {i} \\t accuracy: {correct_pct:.4f} ({mov_acc:.4f})\\t image loss: {img_loss.float():.4f} ({mov_ssim:.4f})\\t cross entropy loss: {acc_loss.float():.4f} ({mov_ce:.4f}) \\t learning rate: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "    # clean up hooks\n",
    "    learner_model.remove_hooks()\n",
    "    teacher_model.remove_hooks()\n",
    "    learner_model.reapply_hooks()\n",
    "    teacher_model.reapply_hooks()\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
