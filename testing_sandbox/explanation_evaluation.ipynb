{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet to prototype and visualize explanation metrics. \n",
    "\n",
    "There are several steps in this workflow. \n",
    "   - Function to compare sensitivity: in both, a small change should result in a small change, and a large change should result in a large change in the explanation.\n",
    "   - Random Noise\n",
    "   - Gaussian blur\n",
    "\n",
    "   \n",
    "   - Function to compare faithfullness (to be completed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def transform_batch_of_images(images):\n",
    "    \"\"\"Apply standard transformation to the batch of images.\"\"\"\n",
    "    # normalise the image to be in the right range\n",
    "    normalize_transform = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "    # convert image to tensor\n",
    "    to_tensor_transform = transforms.ToTensor()\n",
    "    return normalize_transform(to_tensor_transform(images))\n",
    "\n",
    "def get_data(path_to_data:str = '/home/charleshiggins/RL-LRP/baselines/trainVggBaselineForCIFAR10/data'):\n",
    "    \"\"\"Get Dataloader objects from Cifar10 dataset, with path passed in.\n",
    "\n",
    "    Args:\n",
    "        path_to_data (str): path to the data directory\n",
    "    \"\"\"\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=path_to_data, train=False),\n",
    "        batch_size=64, shuffle=False,\n",
    "        num_workers=2, pin_memory=True, transforms=transforms.ToTensor()\n",
    "    )\n",
    "    return val_loader\n",
    "\n",
    "def blur_image_batch(images, kernel_size):\n",
    "    \"\"\"Blur the batch of images using a Gaussian kernel.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): batch of images to be blurred\n",
    "        kernel_size (int): size of the Gaussian kernel\n",
    "    Returns:\n",
    "        torch.Tensor: blurred images\n",
    "    \"\"\"\n",
    "    \n",
    "    blurred_images = torch.stack([TF.gaussian_blur(img, kernel_size=[kernel_size, kernel_size]) for img in images])\n",
    "    return blurred_images\n",
    "\n",
    "def add_random_noise_batch(images, noise_level):\n",
    "    \"\"\"Add random noise to the batch of images.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): images to have noise added\n",
    "        noise_level (float): level of noise to be added\n",
    "    Returns:\n",
    "        torch.Tensor: images with noise added\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(images) * noise_level\n",
    "    noisy_images = images + noise\n",
    "    return noisy_images\n",
    "\n",
    "def compute_distance_between_images(images1, images2):\n",
    "    \"\"\"Compute the distance between two batches of images.\n",
    "\n",
    "    Args:\n",
    "        image1 (torch.Tensor): Tensor of treated images\n",
    "        image2 (torch.Tensor): Tensor of ground-truth images\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of distances between the two images\n",
    "    \"\"\"\n",
    "    # Flatten the images to compute cosine similarity\n",
    "    images1_flat = images1.view(images1.size(0), -1)\n",
    "    images2_flat = images2.view(images2.size(0), -1)\n",
    "    \n",
    "    # Compute cosine similarity and convert to cosine distance\n",
    "    cosine_similarity = F.cosine_similarity(images1_flat, images2_flat)\n",
    "    cosine_distance = 1 - cosine_similarity  # Convert similarity to distance\n",
    "    return cosine_distance\n",
    "\n",
    "\n",
    "def visulise_panel_image(image, model, kernel_size, noise_level):\n",
    "    \"\"\"Visualise the panel of images for the model.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): image to be visualised\n",
    "        model (torch.nn.Module): model to be visualised\n",
    "        kernel_size (int): size of the Gaussian kernel\n",
    "        noise_level (float): level of noise to be added\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "def visualise_panel_image(image, model, kernel_size, noise_level):\n",
    "    \"\"\"Visualise the panel of images for the model.\"\"\"\n",
    "    # Assume the image tensor is already in batch format, if not, unsqueeze it\n",
    "    if image.dim() == 3:\n",
    "        image = image.unsqueeze(0)\n",
    "    \n",
    "    blurred = blur_image_batch(image, kernel_size)\n",
    "    noisy = add_random_noise_batch(image, noise_level)\n",
    "    \n",
    "    outputs = model(image)\n",
    "    blurred_outputs = model(blurred)\n",
    "    noisy_outputs = model(noisy)\n",
    "    \n",
    "    # Display images\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    ax[0].imshow(image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(blurred.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    ax[1].set_title('Blurred Image')\n",
    "    ax[2].imshow(noisy.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    ax[2].set_title('Noisy Image')\n",
    "    ax[3].imshow(outputs.squeeze().detach().permute(1, 2, 0).cpu().numpy())  # Example visualization\n",
    "    ax[3].set_title('Model Output on Original')\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def condense_to_heatmap(images):\n",
    "    \"\"\"\n",
    "    Condense a batch of images to a heatmap by taking the maximum activation across channels.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): A batch of images with dimensions (batch_size, channels, height, width).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of heatmaps with dimensions (batch_size, height, width).\n",
    "    \"\"\"\n",
    "    # Use torch.max to find the maximum across the channels (dim=1)\n",
    "    # max function returns values and indices, so we select values using [0]\n",
    "    heatmaps, _ = torch.max(images, dim=1)\n",
    "    return heatmaps\n",
    "\n",
    "def compute_sparseness_of_heatmap(input_images):\n",
    "    \"\"\"Compute the sparseness of the heatmap.\n",
    "\n",
    "    Args:\n",
    "        heatmap (torch.Tensor): heatmap to be computed\n",
    "    Returns:\n",
    "        float: sparseness of the heatmap\n",
    "    \"\"\"\n",
    "    heatmaps = condense_to_heatmap(input_images)\n",
    "    threshold = 0.01  # Define near-zero threshold\n",
    "    near_zero = (heatmaps.abs() < threshold).float()\n",
    "    sparseness = near_zero.mean(dim=[1, 2])  # Compute mean across spatial dimensions\n",
    "\n",
    "    # Compute Gini coefficient for each heatmap in the batch\n",
    "    batch_size, height, width = heatmaps.size()\n",
    "    gini_indices = torch.empty(batch_size)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        values = heatmaps[i].view(-1)\n",
    "        sorted_values, _ = torch.sort(values)\n",
    "        n = len(values)\n",
    "        cumvals = torch.cumsum(sorted_values, dim=0)\n",
    "        sum_values = cumvals[-1]\n",
    "        gini_index = (2 * torch.arange(1, n+1).to(heatmaps.device) * sorted_values).sum() / (n * sum_values) - (n + 1) / n\n",
    "        gini_indices[i] = 1 - gini_index\n",
    "\n",
    "    return sparseness, gini_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow for the visualisation and data analsysis\n",
    "import torch\n",
    "# Load data\n",
    "# generate the blurred images, noisy images, and the ground truth heatmap images\n",
    "# then for each, calculate the distance between the heatmaps over the blurred images and the ground truth heatmap images\n",
    "def process_batch(\n",
    "    input_batch:torch.Tensor, \n",
    "    input_labels:torch.Tensor,  \n",
    "    methods: list, \n",
    "    kernel_size_min: float, \n",
    "    kernel_size_max:float, \n",
    "    noise_level_min: float, \n",
    "    noise_level_max: float):\n",
    "    \"\"\"Process the batch of images.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model to be visualised\n",
    "        methods (list): list of methods(functions) to be used on each datapoint of form (name, method, model)\n",
    "        kernel_size (int): size of the Gaussian kernel\n",
    "        noise_level (float): level of noise to be added\n",
    "    Returns:\n",
    "        dict: dictionary of distances between the heatmaps\n",
    "    \"\"\"\n",
    "    results_dictionary = {}\n",
    "    for name, method, model in methods:\n",
    "        # get the ground truth heatmap using the method\n",
    "        ground_truth_heatmap = method(input_batch, input_labels, model)\n",
    "        noisy_images_small = add_random_noise_batch(input_batch, noise_level_min)\n",
    "        noisy_images_large = add_random_noise_batch(input_batch, noise_level_max)\n",
    "        blurred_images_small = blur_image_batch(input_batch, kernel_size_min)\n",
    "        blurred_images_large = blur_image_batch(input_batch, kernel_size_max)\n",
    "        # calculate the distance between the heatmaps\n",
    "        distance_noise_small = compute_distance_between_images(ground_truth_heatmap, noisy_images_small)\n",
    "        distance_noise_large = compute_distance_between_images(ground_truth_heatmap, noisy_images_large)\n",
    "        distance_blur_small = compute_distance_between_images(ground_truth_heatmap, blurred_images_small)\n",
    "        distance_blur_large = compute_distance_between_images(ground_truth_heatmap, blurred_images_large)\n",
    "        # calculate sparseness of heatmap\n",
    "        sparseness = compute_sparseness_of_heatmap(ground_truth_heatmap)\n",
    "        # store the results in the dictionary\n",
    "        results_dictionary[f\"{name}_distance_noise_small\"] = distance_noise_small\n",
    "        results_dictionary[f\"{name}_distance_noise_large\"] = distance_noise_large\n",
    "        results_dictionary[f\"{name}_distance_blur_small\"] = distance_blur_small\n",
    "        results_dictionary[f\"{name}_distance_blur_large\"] = distance_blur_large\n",
    "        results_dictionary[f\"{name}_sparseness\"] = sparseness\n",
    "    # return data\n",
    "    return results_dictionary\n",
    "\n",
    "\n",
    "def main():\n",
    "    # define params\n",
    "    kernel_size_min = 3\n",
    "    kernel_size_max = 5\n",
    "    noise_level_min = 0.1\n",
    "    noise_level_max = 0.2\n",
    "    # get the data\n",
    "    data_loader = get_data(\"data\")\n",
    "    # get the model\n",
    "    learner_model = get_learner_model()\n",
    "    teacher_model = get_teacher_model()\n",
    "    # define the methods\n",
    "    methods = [\n",
    "        (\"LRP\", perform_lrp_plain, teacher_model),\n",
    "        (\"LossLRP\", perform_loss_lrp, learner_model),\n",
    "        (\"GradCAM\", perform_gradcam, teacher_model),\n",
    "    ]\n",
    "    # process the data\n",
    "    table = {}\n",
    "    for input_batch, input_labels in data_loader:\n",
    "        results = process_batch(\n",
    "            input_batch, \n",
    "            input_labels, \n",
    "            methods, \n",
    "            kernel_size_min, \n",
    "            kernel_size_max, \n",
    "            noise_level_min, \n",
    "            noise_level_max\n",
    "        )\n",
    "        # print the results\n",
    "        for key, value in results.items():\n",
    "            if key not in table.keys():\n",
    "                table[key] = value\n",
    "            else:\n",
    "                table[key] = torch.cat([table[key], value], dim = 0)\n",
    "    # convert to pandas dataframe\n",
    "    df = pd.DataFrame(table)\n",
    "    # save results\n",
    "    df.to_csv(\"results.csv\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import WrapperNet\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): image to be preprocessed\n",
    "    Returns:\n",
    "        torch.Tensor: preprocessed image\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def perform_lrp_plain(image, label, model):\n",
    "    \"\"\"Perform LRP on the image.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Tensor of images to be explained\n",
    "        labels (torch.Tensor): labels of the image (i.e. the class)\n",
    "        model (torch.nn.Module): model to be visualised\n",
    "    Returns:\n",
    "        torch.Tensor: heatmaps of the image\n",
    "    \"\"\"\n",
    "    assert isinstance(model, WrapperNet), \"Model must be a WrapperNet for LRP\"\n",
    "    output, class_idx = model(image, label)\n",
    "    return output, class_idx\n",
    "\n",
    "def perform_loss_lrp(image, label, model):\n",
    "    \"\"\"Perform LRP on the image using the loss.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Tensor of images to be explained\n",
    "        labels (torch.Tensor): labels of the image (i.e. the class)\n",
    "        model (torch.nn.Module): model to be visualised\n",
    "    Returns:\n",
    "        torch.Tensor: heatmaps of the image\n",
    "    \"\"\"\n",
    "    assert isinstance(model, WrapperNet), \"Model must be a WrapperNet for LossLRP\"\n",
    "    output, class_idx = model(image, label)\n",
    "    return output, class_idx\n",
    "\n",
    "def perform_gradcam(image, label, model):\n",
    "    \"\"\"Perform GradCAM on the image.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Tensor of images to be explained\n",
    "        labels (torch.Tensor): labels of the image (i.e. the class)\n",
    "        model (torch.nn.Module): model to be visualised\n",
    "    Returns:\n",
    "        torch.Tensor: heatmaps of the image\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minatar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
