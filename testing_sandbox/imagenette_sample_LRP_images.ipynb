{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation Notebook\n",
    "The following notebook is used to generate visualisation of LRP for the thesis. \n",
    "By default, I will attempt to use vgg16 or vgg19 pretrained models, and keep things clean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports for the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from experiments import WrapperNet, perform_lrp_plain, evaluate_performance, evaluate_explanations\n",
    "# evaluate_performance, process_dataset, evaluate_explanations\n",
    "from internal_utils import get_data_imagenette, get_data_imagenette, get_vgg16, get_vgg19, preprocess_images, imagenette_to_imagenet_label_mapping_fast, condense_to_heatmap\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRUNCATE = 25\n",
    "print(f\"WARNING: TRUNCATING THE DATASET TO {TRUNCATE} --- THIS WILL ALSO BE TRUNCATED IN THE FUNCTIONS INCLUDED IN THE experiments/run_evaluation.py FILE\")\n",
    "print(f\"TO RUN OVER THE ENTIRE DATASET, UNCOMMENT THE RELEVANT LINES IN THE FUNCTIONS (SEARCH FOR THE STRING 'TRUNCATE')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot comparative figure for the explanation evaluation suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Grid Image: \n",
    "Here, we simply perform LRP on a batch of imagenette data.\n",
    "This is simply to add some color to the thesis, and isn't necessary important, so lots of work will be manual here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualise_grid_image(batch_of_images, batch_of_labels, batch_of_labels_description, method_for_heatmap_generation, model_0, model_1):\n",
    "    \"\"\"Function to generate a pretty plot of 8 images and their corresponding heatmaps\n",
    "    There should be 3 rows. The first row should contain original images, the second row should contain the heatmap by model_0\n",
    "    and the third row should contain the heatmap by model_1.\n",
    "    Each row should have a label describing its content.\n",
    "    \"\"\"\n",
    "    # Get the heatmaps for both models\n",
    "    classifications_0, heatmaps_0 = method_for_heatmap_generation(preprocess_images(batch_of_images), imagenette_to_imagenet_label_mapping_fast(batch_of_labels), model_0)\n",
    "    classifications_1, heatmaps_1 = method_for_heatmap_generation(preprocess_images(batch_of_images), imagenette_to_imagenet_label_mapping_fast(batch_of_labels), model_1)\n",
    "    heatmaps_0 = condense_to_heatmap(heatmaps_0)\n",
    "    heatmaps_1 = condense_to_heatmap(heatmaps_1)\n",
    "\n",
    "    # Number of images to display\n",
    "    num_images = 4\n",
    "\n",
    "    # Setting up the plot\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(2 * num_images, 6))  # Three rows, num_images columns\n",
    "    fig.suptitle('Image and Heatmap Visualizations')\n",
    "\n",
    "    # Row labels\n",
    "    row_labels = ['Raw Image', 'VGG16', 'VGG19']\n",
    "    for i, label in enumerate(row_labels):\n",
    "        fig.text(0.05, 0.75 - i * 0.25, label, va='center', ha='left', fontsize=12, rotation=45, transform=fig.transFigure)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Display original images\n",
    "        ax = axes[0, i]\n",
    "        ax.imshow(batch_of_images[i].permute(1, 2, 0).cpu().numpy())\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Display heatmaps from model 0\n",
    "        ax = axes[1, i]\n",
    "        ax.imshow(heatmaps_0[i], cmap='seismic')\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Display heatmaps from model 1\n",
    "        ax = axes[2, i]\n",
    "        ax.imshow(heatmaps_1[i], cmap='seismic')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0.125, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "train_data, test_data = get_data_imagenette(batch_size=4, shuffle=True)\n",
    "batch_of_images, batch_of_labels = next(iter(test_data))\n",
    "model_0 = WrapperNet(get_vgg16(), hybrid_loss=True)\n",
    "model_1 = WrapperNet(get_vgg19(), hybrid_loss=True)\n",
    "visualise_grid_image(batch_of_images, batch_of_labels, [], perform_lrp_plain, model_0, model_1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluation suite "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_comparative_figure(df, method_0, method_1, data_type=\"Train\"):\n",
    "    \"\"\"\n",
    "    Plot a comparative figure of the results between the two models.\n",
    "    \"\"\"\n",
    "    figs_per_row = [\"distance_noise_small\", \"distance_noise_large\", \"distance_blur_small\", \"distance_blur_large\"]\n",
    "\n",
    "    # Create a single row figure with two boxplots per column\n",
    "    fig, axs = plt.subplots(1, len(figs_per_row), figsize=(20, 5), sharey=True)\n",
    "\n",
    "    for j, fig_type in enumerate(figs_per_row):\n",
    "        # Filter data for method_0\n",
    "        if \"small\" in fig_type:\n",
    "            df_method_0 = df[df[f\"{method_0}_{fig_type}_class_change\"] == False]\n",
    "        else:\n",
    "            df_method_0 = df[df[f\"{method_0}_{fig_type}_class_change\"] == True]\n",
    "        \n",
    "        # Filter data for method_1\n",
    "        if \"small\" in fig_type:\n",
    "            df_method_1 = df[df[f\"{method_1}_{fig_type}_class_change\"] == False]\n",
    "        else:\n",
    "            df_method_1 = df[df[f\"{method_1}_{fig_type}_class_change\"] == True]\n",
    "\n",
    "        # Combine the data for boxplot using a hue for methods\n",
    "        combined_df = pd.DataFrame({\n",
    "            'Value': pd.concat([df_method_0[f\"{method_0}_{fig_type}\"], df_method_1[f\"{method_1}_{fig_type}\"]]),\n",
    "            'Method': [method_0] * len(df_method_0) + [method_1] * len(df_method_1)\n",
    "        })\n",
    "\n",
    "        # Create boxplot\n",
    "        sns.boxplot(x='Method', y='Value', hue= 'Method', data=combined_df, ax=axs[j])\n",
    "        axs[j].set_title(f\"{fig_type}\".replace(\"_\", \" \"))\n",
    "    fig.suptitle(f\"Comparative Analysis of {method_0} and {method_1} on {data_type} Data\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation driver method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_data, test_data = get_data_imagenette()\n",
    "vgg16_results_train, vgg16_results_test = evaluate_performance(get_vgg16(), train_data, test_data)\n",
    "vgg19_results_train, vgg19_results_test = evaluate_performance(get_vgg19(), train_data, test_data)\n",
    "\n",
    "# visualise results from the initial dataframes\n",
    "vgg16_results_train['model'] = 'VGG16'\n",
    "vgg16_results_test['model'] = 'VGG16'\n",
    "vgg19_results_train['model'] = 'VGG19'\n",
    "vgg19_results_test['model'] = 'VGG19'\n",
    "\n",
    "# Concatenate dataframes\n",
    "combined_df_train = pd.concat([vgg16_results_train, vgg19_results_train])\n",
    "combined_df_test = pd.concat([vgg16_results_test, vgg19_results_test])\n",
    "\n",
    "# Melt the dataframe to long format for seaborn\n",
    "melted_df_train = combined_df_train.melt(id_vars=['model'], var_name='metric', value_name='value')\n",
    "melted_df_test = combined_df_test.melt(id_vars=['model'], var_name='metric', value_name='value')\n",
    "\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='metric', y='value', hue='model', data=melted_df_train)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(title='Model (Train)')\n",
    "plt.show()\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='metric', y='value', hue='model', data=melted_df_test)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(title='Model (Trdy)')\n",
    "plt.show()\n",
    "\n",
    "# To evaluate the explanations, we need to pass in a list of \"methods\"\n",
    "# each method is a tuple of the form (name, method, model)\n",
    "# name is a string which identifies the method -- i.e. \"VGG16\"\n",
    "# method is a function which generates a heatmap on a certain model --- i.e. perform_lrp_plain\n",
    "# model is the model which the method is applied to --- it needs to be in the heatmap form (i.e.)\n",
    "vgg16 = get_vgg16()\n",
    "vgg19 = get_vgg19()\n",
    "methods = [\n",
    "        (\"VGG16\", perform_lrp_plain, WrapperNet(vgg16, hybrid_loss=True)),\n",
    "        (\"VGG19\", perform_lrp_plain, WrapperNet(vgg19, hybrid_loss=True))\n",
    "    ]\n",
    "# now evaluate explanations\n",
    "df_train, df_test = evaluate_explanations(train_data, test_data, methods, save_results = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparative_figure(df_test, \"VGG16\", \"VGG19\", \"Test\")\n",
    "plot_comparative_figure(df_train, \"VGG16\", \"VGG19\", \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
