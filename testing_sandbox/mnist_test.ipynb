{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.247748\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "Inner Network Test Loss: 0.0023, Accuracy: 13.15%\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n",
      "size of hooks dict: 7\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.031637\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.linear.Linear'>\n",
      "reversing layer of type <class 'torch.nn.modules.activation.ReLU'>\n",
      "encounterted a ReLu Layer\n",
      "reversing layer of type <class 'torch.nn.modules.conv.Conv2d'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 104\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):  \u001b[38;5;66;03m# 10\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    107\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[7], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(wrapped_model, device, train_loader, optimizer, epoch, target_accuracy)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100.\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mbatch_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# wandb.log({\"Test Accuracy\": accuracy})\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m# if accuracy >= target_accuracy:\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m#     print(f\"Stopping early: Reached {accuracy:.2f}% accuracy\")\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m#     return True\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 66\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(wrapped_model, device, test_loader)\u001b[0m\n\u001b[1;32m     64\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     65\u001b[0m target_map \u001b[38;5;241m=\u001b[39m apply_threshold(data, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(output, target_map)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# sum up batch loss\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# correct += pred.eq(target.view_as(pred)).sum().item()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/minatar/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/minatar/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/experiments/lrp_wrapper.py:44\u001b[0m, in \u001b[0;36mDiffLrpWrapper.forward\u001b[0;34m(self, x, target_class)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, actual_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mnamed_modules())[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(actual_module\u001b[38;5;241m.\u001b[39mchildren())) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# if the module is a leaf module, apply LRP\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m         relevance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_lrp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# normalise output so that it sums to 1 in total --- all outputs are also in same range\u001b[39;00m\n\u001b[1;32m     46\u001b[0m sum_of_pixels \u001b[38;5;241m=\u001b[39m relevance\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/experiments/lrp_wrapper.py:64\u001b[0m, in \u001b[0;36mDiffLrpWrapper._apply_lrp\u001b[0;34m(self, name, layer, relevance_to_be_propagaed)\u001b[0m\n\u001b[1;32m     62\u001b[0m     relevance_to_be_propagaed \u001b[38;5;241m=\u001b[39m relevance_to_be_propagaed\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs[name]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Get the relevance of the output & apply LRP\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m relevance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_layer_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_activation_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance_to_be_propagaed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m relevance\n",
      "File \u001b[0;32m~/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/experiments/lrp_wrapper.py:72\u001b[0m, in \u001b[0;36mDiffLrpWrapper._reverse_layer_\u001b[0;34m(self, activations_at_start, layer, relevance)\u001b[0m\n\u001b[1;32m     70\u001b[0m     R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrp_linear(layer, activations_at_start, relevance)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv2d):\n\u001b[0;32m---> 72\u001b[0m     R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlrp_conv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations_at_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencounterted a ReLu Layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/experiments/lrp_wrapper.py:112\u001b[0m, in \u001b[0;36mDiffLrpWrapper.lrp_conv2d\u001b[0;34m(self, layer, activation, R, eps)\u001b[0m\n\u001b[1;32m    110\u001b[0m Z \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(X, W, bias\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39mbias, stride\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39mstride, padding\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39mpadding) \u001b[38;5;241m+\u001b[39m eps\n\u001b[1;32m    111\u001b[0m S \u001b[38;5;241m=\u001b[39m R \u001b[38;5;241m/\u001b[39m Z\n\u001b[0;32m--> 112\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m R_new \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m C\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m R_new\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/charleshiggins/Personal/CharlesPhD/CodeRepo/xai_intervention/RL-LRP/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from experiments import DiffLrpWrapper, SimpleRNet, apply_threshold\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"reverse_LRP_mnist\", tags=[\"diff_lrp\", \"mnist\", \"simplernet\"], mode=\"disabled\")\n",
    "\n",
    "# Load and transform the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Initialize the network and optimizer for the underlying network\n",
    "model = SimpleRNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "# now wrap the network in the LRP class\n",
    "wrapped_model = DiffLrpWrapper(model)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "wrapped_model.to(device)\n",
    "\n",
    "def test_inner_net(wrapped_model, device, test_loader):\n",
    "    net = wrapped_model.net\n",
    "    new_criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # target_map = apply_threshold(data)\n",
    "            output = torch.nn.functional.softmax(net(data), dim=1)\n",
    "            test_loss += new_criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    wandb.log({\"Inner Network Loss\": test_loss, \"Inner Network Accuracy\": accuracy})\n",
    "    print(f'Inner Network Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Function to test the model\n",
    "def test(wrapped_model, device, test_loader):\n",
    "    wrapped_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target_map = apply_threshold(data, threshold=0.9)\n",
    "        output = wrapped_model(data, target.unsqueeze(1))\n",
    "        test_loss += criterion(output, target_map).item()  # sum up batch loss\n",
    "            # pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            # correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    wandb.log({\"Test Loss\": test_loss})\n",
    "    underlying_network_accuracy = test_inner_net(wrapped_model, device, test_loader)\n",
    "    return test_loss\n",
    "\n",
    "# Training the model with early stopping\n",
    "def train(wrapped_model, device, train_loader, optimizer, epoch, target_accuracy=99.0):\n",
    "    wrapped_model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target_map = apply_threshold(data, threshold=0.9)\n",
    "        optimizer.zero_grad()\n",
    "        # print(target.unsqueeze(1))\n",
    "        output = wrapped_model(data, target.unsqueeze(1))\n",
    "        loss = criterion(output, target_map)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({\"Train Loss\": loss.item()})\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "            accuracy = test(wrapped_model, device, test_loader)\n",
    "            # wandb.log({\"Test Accuracy\": accuracy})\n",
    "            # if accuracy >= target_accuracy:\n",
    "            #     print(f\"Stopping early: Reached {accuracy:.2f}% accuracy\")\n",
    "            #     return True\n",
    "    return False\n",
    "\n",
    "# Run training\n",
    "for epoch in range(1, 11):  # 10\n",
    "    if train(wrapped_model, device, train_loader, optimizer, epoch):\n",
    "        break\n",
    "    \n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleshiggins/miniconda3/envs/minatar/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/charleshiggins/miniconda3/envs/minatar/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/charleshiggins/miniconda3/envs/minatar/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /Users/charleshiggins/miniconda3/envs/minatar/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_mnist(batch_size=64):\n",
    "    \"\"\" Load MNIST dataset with torchvision. \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to PyTorch tensors\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalizes the dataset\n",
    "    ])\n",
    "    \n",
    "    train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "def apply_threshold(images, threshold=0.5):\n",
    "    \"\"\" Apply a threshold to the images, setting all pixels below the threshold to zero.\n",
    "        Images should retain original dimensions.\n",
    "    \"\"\"\n",
    "    # Thresholding\n",
    "    thresholded_images = torch.where(images > threshold, images, torch.zeros_like(images))\n",
    "    return thresholded_images\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_loader = load_mnist(batch_size=10)\n",
    "\n",
    "# Get a single batch of images\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Apply threshold\n",
    "thresholded_images = apply_threshold(images, threshold=0.95)  # Using 0.5 as an example threshold\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(images[0][0], cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[1].imshow(thresholded_images[0][0], cmap='gray')\n",
    "axes[1].set_title('Thresholded Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images, labels = next(data_iter)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrapped_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_model\u001b[49m(images, labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wrapped_model' is not defined"
     ]
    }
   ],
   "source": [
    "outputs = wrapped_model(images, labels.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(apply_threshold(images)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(\u001b[43moutputs\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput Image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(apply_threshold(images)[0][0], cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[1].imshow(outputs.detach()[0][0], cmap='hot')\n",
    "axes[1].set_title('Output Image')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3141e-03,  1.9478e-02,  3.9422e-02,  6.4557e-02,  9.5678e-02,\n",
       "          1.2046e-01,  1.3839e-01,  1.4954e-01,  1.5549e-01,  1.5543e-01,\n",
       "          1.5542e-01,  1.5544e-01,  1.5549e-01,  1.5557e-01,  1.5566e-01,\n",
       "          1.5574e-01,  1.5583e-01,  1.5591e-01,  1.5600e-01,  1.5609e-01,\n",
       "          1.4983e-01,  1.3669e-01,  1.1673e-01,  9.1522e-02,  6.0278e-02,\n",
       "          3.5365e-02,  1.7309e-02,  6.0384e-03],\n",
       "        [ 1.8260e-02,  5.7282e-02,  1.1568e-01,  1.9048e-01,  2.8327e-01,\n",
       "          3.5775e-01,  4.1143e-01,  4.4572e-01,  4.6358e-01,  4.6343e-01,\n",
       "          4.6338e-01,  4.6344e-01,  4.6357e-01,  4.6377e-01,  4.3467e-01,\n",
       "          4.0091e-01,  3.6685e-01,  3.7185e-01,  4.0034e-01,  4.3487e-01,\n",
       "          4.4138e-01,  4.0818e-01,  3.4975e-01,  2.7475e-01,  1.8163e-01,\n",
       "          1.0680e-01,  5.2755e-02,  1.8125e-02],\n",
       "        [ 3.6553e-02,  1.1452e-01,  2.3011e-01,  3.7993e-01,  5.6400e-01,\n",
       "          7.1142e-01,  8.1734e-01,  8.8556e-01,  9.1954e-01,  9.1928e-01,\n",
       "          9.1920e-01,  9.1932e-01,  6.0593e-01,  2.8620e-01,  2.1031e-01,\n",
       "          1.2014e-01,  3.1190e-02,  3.8565e-01,  8.0411e-01,  8.8654e-01,\n",
       "          8.9651e-01,  8.0857e-01,  6.9295e-01,  5.4280e-01,  3.5811e-01,\n",
       "          2.1001e-01,  1.0338e-01,  3.4486e-02],\n",
       "        [ 5.9961e-02,  1.8816e-01,  3.7915e-01,  6.2838e-01,  9.2845e-01,\n",
       "          1.1684e+00,  1.3400e+00,  1.4486e+00,  1.4990e+00,  1.4986e+00,\n",
       "          1.4986e+00,  1.0808e+00,  2.3033e-01, -6.8639e-01,  4.9489e-01,\n",
       "          1.0992e+00, -4.6956e-02, -3.5732e-01,  7.0621e-01,  1.3675e+00,\n",
       "          1.4393e+00,  1.3049e+00,  1.1254e+00,  8.7565e-01,  5.7460e-01,\n",
       "          3.3353e-01,  1.6084e-01,  5.1190e-02],\n",
       "        [ 8.8611e-02,  2.7745e-01,  5.6039e-01,  9.2861e-01,  1.3633e+00,\n",
       "          1.7092e+00,  1.9546e+00,  2.1058e+00,  2.1718e+00,  2.1714e+00,\n",
       "          2.1714e+00,  1.0205e+00, -6.1944e-01, -1.5523e+00,  3.6403e+00,\n",
       "          3.9188e+00,  1.7304e+00, -1.2324e+00,  5.8341e-01,  1.9513e+00,\n",
       "          2.0971e+00,  1.9255e+00,  1.6192e+00,  1.2503e+00,  8.1415e-01,\n",
       "          4.6670e-01,  2.1961e-01,  6.7012e-02],\n",
       "        [ 1.1093e-01,  3.4721e-01,  7.0212e-01,  1.1642e+00,  1.7023e+00,\n",
       "          2.1292e+00,  2.4308e+00,  2.6135e+00,  2.6893e+00,  2.6889e+00,\n",
       "          2.3067e+00,  4.0076e-01, -1.5078e+00,  3.5814e+00,  6.3226e+00,\n",
       "          3.3527e+00,  4.7327e+00,  1.6223e+00,  1.1767e-01,  2.2016e+00,\n",
       "          2.6875e+00,  2.4396e+00,  1.9963e+00,  1.5333e+00,  9.9349e-01,\n",
       "          5.6464e-01,  2.6114e-01,  7.6771e-02],\n",
       "        [ 1.2763e-01,  3.9868e-01,  8.0703e-01,  1.3383e+00,  1.9492e+00,\n",
       "          2.4323e+00,  2.7722e+00,  2.9746e+00,  3.0542e+00,  2.9674e+00,\n",
       "          2.4005e+00, -1.7833e-01,  2.0426e+00,  5.8891e+00,  2.9912e+00,\n",
       "         -3.8279e+00,  6.1700e+00,  3.3886e+00, -2.1400e-01,  2.6282e+00,\n",
       "          3.1333e+00,  2.8114e+00,  2.2569e+00,  1.7245e+00,  1.1117e+00,\n",
       "          6.2649e-01,  2.8452e-01,  8.0499e-02],\n",
       "        [ 1.3797e-01,  4.3066e-01,  8.7368e-01,  1.4488e+00,  2.1029e+00,\n",
       "          2.6189e+00,  2.9806e+00,  3.1917e+00,  3.2709e+00,  3.0332e+00,\n",
       "          2.0934e+00,  1.2029e-01,  3.3818e+00,  5.3336e+00, -6.1652e+00,\n",
       "         -3.3094e-01,  6.9306e+00,  3.8788e+00, -2.3199e-01,  3.0235e+00,\n",
       "          3.4286e+00,  3.0615e+00,  2.4069e+00,  1.8306e+00,  1.1745e+00,\n",
       "          6.5626e-01,  2.9251e-01,  7.9921e-02],\n",
       "        [ 1.4318e-01,  4.4617e-01,  9.0556e-01,  1.5001e+00,  2.1725e+00,\n",
       "          2.7018e+00,  3.0719e+00,  3.2853e+00,  3.2904e+00,  2.9789e+00,\n",
       "          6.0872e-01,  2.7466e-03,  2.3749e+00, -2.1203e+00, -6.8732e+00,\n",
       "          4.4053e+00,  5.6983e+00,  2.0687e+00,  3.9535e-01,  3.2562e+00,\n",
       "          3.6045e+00,  3.1668e+00,  2.4676e+00,  1.8716e+00,  1.1971e+00,\n",
       "          6.6553e-01,  2.9359e-01,  7.8955e-02],\n",
       "        [ 1.4315e-01,  4.4603e-01,  9.0525e-01,  1.4996e+00,  2.1719e+00,\n",
       "          2.7011e+00,  3.0712e+00,  3.2848e+00,  3.2271e+00,  1.4571e+00,\n",
       "         -1.3621e+00, -6.7422e-01, -2.5892e-01, -2.2774e+00, -4.2654e+00,\n",
       "          3.0281e+00,  4.1279e+00,  4.9848e-02,  1.1104e+00,  3.4198e+00,\n",
       "          3.6273e+00,  3.1190e+00,  2.4669e+00,  1.8710e+00,  1.1966e+00,\n",
       "          6.6524e-01,  2.9344e-01,  7.8909e-02],\n",
       "        [ 1.4311e-01,  4.4587e-01,  9.0493e-01,  1.4991e+00,  2.1712e+00,\n",
       "          2.7003e+00,  3.0705e+00,  3.2842e+00,  3.1422e+00,  5.3852e-01,\n",
       "         -2.2963e+00, -3.8312e-02,  1.1102e+00, -2.6351e-01, -1.6543e+00,\n",
       "          3.0413e+00,  2.7436e+00, -3.5154e-01,  1.9996e+00,  3.8125e+00,\n",
       "          3.5806e+00,  3.0492e+00,  2.4664e+00,  1.8705e+00,  1.1962e+00,\n",
       "          6.6495e-01,  2.9330e-01,  7.8859e-02],\n",
       "        [ 1.4306e-01,  4.4572e-01,  9.0462e-01,  1.4986e+00,  2.1705e+00,\n",
       "          2.6995e+00,  3.0697e+00,  3.2835e+00,  3.1309e+00,  5.6275e-01,\n",
       "         -1.2271e+00,  3.1145e+00,  2.3083e+00,  3.7591e-01,  2.9673e-01,\n",
       "          2.2053e+00,  1.2559e+00,  1.5939e-01,  2.6249e+00,  3.8503e+00,\n",
       "          3.5190e+00,  2.9940e+00,  2.4659e+00,  1.8700e+00,  1.1958e+00,\n",
       "          6.6470e-01,  2.9317e-01,  7.8815e-02],\n",
       "        [ 1.4302e-01,  4.4559e-01,  9.0436e-01,  1.4981e+00,  2.1699e+00,\n",
       "          2.6988e+00,  3.0689e+00,  3.2828e+00,  3.1329e+00,  2.5347e+00,\n",
       "          2.6661e+00,  3.5497e+00,  2.3123e+00,  6.4257e-02,  2.7166e-01,\n",
       "          1.8320e+00, -7.1670e-02,  8.0114e-01,  3.2117e+00,  3.8141e+00,\n",
       "          3.4684e+00,  2.9259e+00,  2.4655e+00,  1.8695e+00,  1.1954e+00,\n",
       "          6.6449e-01,  2.9306e-01,  7.8784e-02],\n",
       "        [ 1.4300e-01,  4.4552e-01,  9.0421e-01,  1.4979e+00,  2.1695e+00,\n",
       "          2.6983e+00,  3.0684e+00,  3.2822e+00,  3.2169e+00,  3.1598e+00,\n",
       "          3.3294e+00,  3.2464e+00,  1.1772e+00, -1.6505e+00,  2.8894e+00,\n",
       "          3.0088e+00,  1.4694e+00,  6.5366e-01,  3.3624e+00,  3.7688e+00,\n",
       "          3.4207e+00,  2.9254e+00,  2.4650e+00,  1.8692e+00,  1.1952e+00,\n",
       "          6.6436e-01,  2.9300e-01,  7.8772e-02],\n",
       "        [ 1.4299e-01,  4.4550e-01,  9.0414e-01,  1.4978e+00,  2.1693e+00,\n",
       "          2.6981e+00,  3.0681e+00,  3.2819e+00,  3.3008e+00,  3.2847e+00,\n",
       "          3.3883e+00,  2.6659e+00, -2.6791e-01, -2.4105e+00,  4.4845e+00,\n",
       "          4.4594e+00, -1.3900e-01,  4.4643e-01,  3.5111e+00,  3.7216e+00,\n",
       "          3.3508e+00,  2.9250e+00,  2.4648e+00,  1.8690e+00,  1.1952e+00,\n",
       "          6.6432e-01,  2.9299e-01,  7.8781e-02],\n",
       "        [ 1.4300e-01,  4.4553e-01,  9.0419e-01,  1.4978e+00,  2.1694e+00,\n",
       "          2.6982e+00,  3.0681e+00,  3.2819e+00,  3.3612e+00,  3.3623e+00,\n",
       "          3.3635e+00,  1.8638e+00, -1.5792e+00,  2.7284e+00,  5.1652e+00,\n",
       "          4.2135e+00, -1.9088e+00,  1.0546e+00,  3.7517e+00,  3.6742e+00,\n",
       "          3.2956e+00,  2.9248e+00,  2.4647e+00,  1.8690e+00,  1.1952e+00,\n",
       "          6.6436e-01,  2.9303e-01,  7.8801e-02],\n",
       "        [ 1.4302e-01,  4.4560e-01,  9.0432e-01,  1.4980e+00,  2.1697e+00,\n",
       "          2.6985e+00,  3.0685e+00,  3.2823e+00,  3.3614e+00,  3.3624e+00,\n",
       "          2.7705e+00,  4.6847e-01, -2.6548e+00,  4.1674e+00,  5.7526e+00,\n",
       "          9.1253e-01, -1.7482e+00,  1.9731e+00,  3.8895e+00,  3.5621e+00,\n",
       "          3.2277e+00,  2.9247e+00,  2.4647e+00,  1.8691e+00,  1.1953e+00,\n",
       "          6.6442e-01,  2.9307e-01,  7.8822e-02],\n",
       "        [ 1.4306e-01,  4.4572e-01,  9.0456e-01,  1.4984e+00,  2.1703e+00,\n",
       "          2.6992e+00,  3.0692e+00,  3.2829e+00,  2.9747e+00,  2.4061e+00,\n",
       "          1.1255e+00, -1.9694e+00, -3.4078e+00,  7.3404e+00,  6.9541e+00,\n",
       "          1.4214e-01, -1.4443e+00,  2.1983e+00,  3.7874e+00,  3.4928e+00,\n",
       "          3.2278e+00,  2.9248e+00,  2.4649e+00,  1.8693e+00,  1.1954e+00,\n",
       "          6.6453e-01,  2.9314e-01,  7.8846e-02],\n",
       "        [ 1.4310e-01,  4.4585e-01,  9.0483e-01,  1.4989e+00,  2.1709e+00,\n",
       "          2.7000e+00,  3.0700e+00,  3.2837e+00,  2.4295e+00,  1.1460e+00,\n",
       "         -8.4376e-01, -4.3353e+00, -2.2493e+00,  8.9538e+00,  6.5346e+00,\n",
       "         -3.9208e+00, -1.3210e+00,  2.0354e+00,  3.4421e+00,  3.2671e+00,\n",
       "          3.0803e+00,  2.8489e+00,  2.4506e+00,  1.8695e+00,  1.1956e+00,\n",
       "          6.6464e-01,  2.9320e-01,  7.8866e-02],\n",
       "        [ 1.4314e-01,  4.4600e-01,  9.0515e-01,  1.4994e+00,  2.1717e+00,\n",
       "          2.7010e+00,  3.0711e+00,  2.7437e+00,  4.5339e-01,  1.4062e-02,\n",
       "         -1.8474e+00, -4.0388e+00,  7.0919e+00,  1.0775e+01,  9.7985e-01,\n",
       "         -5.1086e+00, -1.5085e+00,  1.5991e+00,  3.0582e+00,  2.9757e+00,\n",
       "          2.4779e+00,  2.8730e+00,  2.4979e+00,  1.8696e+00,  1.1957e+00,\n",
       "          6.6472e-01,  2.9325e-01,  7.8877e-02],\n",
       "        [ 1.3686e-01,  4.2666e-01,  8.6605e-01,  1.4354e+00,  2.0768e+00,\n",
       "          2.5815e+00,  2.8748e+00, -1.3098e+00, -8.0043e-01,  1.2556e+00,\n",
       "          4.4092e+00,  7.7981e+00,  1.0863e+01,  1.0986e+01,  2.2513e+00,\n",
       "         -2.3673e+00, -1.3071e+00,  1.1056e+00,  9.2446e-02, -7.6033e-01,\n",
       "          1.5278e+00,  2.8679e+00,  2.4539e+00,  1.7785e+00,  1.1357e+00,\n",
       "          6.2956e-01,  2.7604e-01,  7.2865e-02],\n",
       "        [ 1.2495e-01,  3.8899e-01,  7.9011e-01,  1.3101e+00,  1.8900e+00,\n",
       "          2.3452e+00,  2.6112e+00,  9.5954e-01, -5.8228e-01,  1.2835e+00,\n",
       "          4.2479e+00,  6.7706e+00,  9.0828e+00,  8.8754e+00,  6.2957e+00,\n",
       "          3.4130e+00,  1.0418e+00, -7.1155e-01, -2.1387e+00,  1.8833e+00,\n",
       "          2.9002e+00,  2.7607e+00,  2.2786e+00,  1.5959e+00,  1.0148e+00,\n",
       "          5.5841e-01,  2.4074e-01,  6.0821e-02],\n",
       "        [ 1.0667e-01,  3.3186e-01,  6.7594e-01,  1.1211e+00,  1.6100e+00,\n",
       "          1.9923e+00,  2.1889e+00,  2.2403e+00,  7.0831e-01, -8.6468e-01,\n",
       "         -8.3503e-01,  4.6676e+00,  1.1024e+00,  1.0889e+00,  4.0102e+00,\n",
       "          2.0836e+00,  2.7681e-01, -3.5823e-01,  1.4583e+00,  2.5812e+00,\n",
       "          2.7050e+00,  2.4882e+00,  1.9523e+00,  1.3285e+00,  8.3880e-01,\n",
       "          4.5550e-01,  1.9027e-01,  4.4507e-02],\n",
       "        [ 8.3272e-02,  2.5829e-01,  5.2709e-01,  8.7294e-01,  1.2460e+00,\n",
       "          1.5358e+00,  1.6669e+00,  1.6878e+00,  9.6622e-01, -1.2663e-01,\n",
       "         -1.2598e+00, -2.2842e+00, -2.8681e+00, -2.8773e+00, -1.7144e+00,\n",
       "         -5.5429e-01,  6.5882e-01,  1.4017e+00,  1.9543e+00,  2.2012e+00,\n",
       "          2.1574e+00,  1.8786e+00,  1.4541e+00,  9.9637e-01,  6.2279e-01,\n",
       "          3.3227e-01,  1.3294e-01,  2.7839e-02],\n",
       "        [ 5.4621e-02,  1.6902e-01,  3.4590e-01,  5.7278e-01,  8.1116e-01,\n",
       "          9.9505e-01,  1.0713e+00,  1.0686e+00,  1.0288e+00,  7.1681e-01,\n",
       "          2.2844e-01, -2.3838e-01, -3.1209e-01, -3.0387e-01,  1.8112e-01,\n",
       "          6.8897e-01,  1.2407e+00,  1.3879e+00,  1.3900e+00,  1.4443e+00,\n",
       "          1.3502e+00,  1.1654e+00,  9.0372e-01,  6.2240e-01,  3.8368e-01,\n",
       "          1.9934e-01,  7.4267e-02,  1.2042e-02],\n",
       "        [ 3.2300e-02,  9.9241e-02,  2.0412e-01,  3.3709e-01,  4.7200e-01,\n",
       "          5.7474e-01,  6.4317e-01,  6.3709e-01,  6.2887e-01,  6.5406e-01,\n",
       "          6.5917e-01,  6.8361e-01,  7.0085e-01,  7.2571e-01,  7.4793e-01,\n",
       "          7.4808e-01,  7.8201e-01,  7.9843e-01,  8.1778e-01,  8.0354e-01,\n",
       "          7.2402e-01,  6.1821e-01,  4.7260e-01,  3.3953e-01,  2.0445e-01,\n",
       "          1.0146e-01,  3.2754e-02,  2.2872e-03],\n",
       "        [ 1.5593e-02,  4.7728e-02,  9.9076e-02,  1.6269e-01,  2.2465e-01,\n",
       "          2.7109e-01,  3.0116e-01,  3.1186e-01,  3.1036e-01,  3.1038e-01,\n",
       "          2.8617e-01,  2.7933e-01,  2.9625e-01,  3.2230e-01,  3.4954e-01,\n",
       "          3.4959e-01,  3.7389e-01,  3.8082e-01,  3.6395e-01,  3.3797e-01,\n",
       "          2.9519e-01,  2.6308e-01,  2.1174e-01,  1.4809e-01,  8.6063e-02,\n",
       "          3.9509e-02,  9.3223e-03, -1.4602e-03],\n",
       "        [ 5.2409e-03,  1.5651e-02,  3.2181e-02,  5.1773e-02,  7.0395e-02,\n",
       "          8.3799e-02,  9.2094e-02,  9.4214e-02,  9.3285e-02,  9.3293e-02,\n",
       "          9.3318e-02,  9.3352e-02,  9.3381e-02,  9.3405e-02,  9.3414e-02,\n",
       "          9.3409e-02,  9.3394e-02,  9.3384e-02,  9.3377e-02,  9.3380e-02,\n",
       "          8.8147e-02,  7.7746e-02,  6.1217e-02,  4.1616e-02,  2.2974e-02,\n",
       "          9.5424e-03,  1.2197e-03, -9.2213e-04]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.detach()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Distance Loss: 1.0005197525024414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CosineDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Flatten the images: shape from [b, 1, 28, 28] to [b, 784]\n",
    "        input1_flat = input1.view(input1.size(0), -1)\n",
    "        input2_flat = input2.view(input2.size(0), -1)\n",
    "        \n",
    "        # Compute cosine similarity, then convert to cosine distance\n",
    "        cosine_sim = F.cosine_similarity(input1_flat, input2_flat)\n",
    "        cosine_dist = 1 - cosine_sim\n",
    "        \n",
    "        # Calculate the mean of the cosine distances\n",
    "        loss = cosine_dist.mean()\n",
    "        return loss\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Random tensors simulating image batches\n",
    "    img1 = torch.randn(10, 1, 28, 28)  # Batch of 10 images\n",
    "    img2 = torch.randn(10, 1, 28, 28)  # Batch of 10 images\n",
    "    \n",
    "    # Initialize the loss function\n",
    "    loss_func = CosineDistanceLoss()\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = loss_func(img1, img2)\n",
    "    print(\"Cosine Distance Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minatar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
