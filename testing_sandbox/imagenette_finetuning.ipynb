{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP Fine tuning\n",
    "The objective of this notebook is to demonstrate that one can optimise a network post training. \n",
    "We demonstrate here that by incorporating attention information, we can improve the quality of models. \n",
    "This has several steps: \n",
    "- Download the Imagenette dataset (we use this rather than the full imagenet as it is considerably more lightweight)\n",
    "- Download two pre-trained models on Imagenet (from the VGG family)\n",
    "- Evaluate the quality of the models on the dataset. \n",
    "- Use the better performing model as the \"teacher model\" \n",
    "- Attempt to improve the learner model using the teacher's heatmaps. \n",
    "- Periodically evaluate performance\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from experiments import process_batch, WrapperNet, perform_lrp_plain\n",
    "from internal_utils import get_data_imagenette, preprocess_images\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRUNCATE = 3\n",
    "\n",
    "def imagenette_to_imagenet_label_mapping(imagenette_labels):\n",
    "    mapping = {\n",
    "        0: 0,    # tench\n",
    "        1: 217,  # English Springer\n",
    "        2: 482,  # Cassette Player\n",
    "        3: 491,  # Chain Saw\n",
    "        4: 497,  # Church\n",
    "        5: 566,  # French Horn\n",
    "        6: 569,  # Garbage Truck\n",
    "        7: 571,  # Gas Pump\n",
    "        8: 574,  # Golf Ball\n",
    "        9: 701   # Parachute\n",
    "    }\n",
    "    \n",
    "    # Assuming imagenette_labels is a list\n",
    "    output = [mapping[label.item()] for label in imagenette_labels]\n",
    "    return output\n",
    "\n",
    "def imagenette_to_imagenet_label_mapping_fast(imagenette_labels):\n",
    "    # a vectorised version of the mapping above\n",
    "    mapping = torch.tensor([0, 217, 482, 491, 497, 566, 569, 571, 574, 701])\n",
    "    \n",
    "    # Use the imagenette_labels as indices to map to the corresponding imagenet labels\n",
    "    output = mapping[imagenette_labels]\n",
    "    return output\n",
    "\n",
    "def get_vgg16():\n",
    "    \"\"\"Download a pretrained vgg16 on Imagenet\"\"\"\n",
    "    vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    vgg16.eval()\n",
    "    return vgg16\n",
    "    \n",
    "def get_vgg19():\n",
    "    \"\"\" Download a pretrained vgg19 on Imagenet\"\"\"\n",
    "    vgg19 = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "    vgg19.eval() \n",
    "    return vgg19\n",
    "    \n",
    "    \n",
    "def evaluate_performance(model, train_data, test_data):\n",
    "    \"\"\"Evaluate the performance of the model on the data\"\"\"\n",
    "    train_loss, train_accuracy = [], []\n",
    "    test_loss, test_accuracy = [], []\n",
    "    model.to(device)\n",
    "    # for i, (input, label) in enumerate(train_data):\n",
    "    for i in tqdm(range(0, TRUNCATE)):\n",
    "        input, label = next(iter(train_data))\n",
    "        input = preprocess_images(input).to(device)\n",
    "        label = imagenette_to_imagenet_label_mapping_fast(label).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "        loss = torch.nn.functional.cross_entropy(output, label)\n",
    "        accuracy = (output.argmax(dim=1) == label).float().mean() * 100\n",
    "        train_loss.append(loss)\n",
    "        train_accuracy.append(accuracy)\n",
    "    # for i, (input, label) in enumerate(test_data):\n",
    "    for i in tqdm(range(0, TRUNCATE)):\n",
    "        input, label = next(iter(test_data))\n",
    "        input = preprocess_images(input).to(device)\n",
    "        label = imagenette_to_imagenet_label_mapping_fast(label).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "        loss = torch.nn.functional.cross_entropy(output, label)\n",
    "        accuracy = (output.argmax(dim=1) == label).float().mean() * 100\n",
    "        test_loss.append(loss)\n",
    "        test_accuracy.append(accuracy)\n",
    "    # convert results to dictionary\n",
    "    results = {\n",
    "        \"train_loss\": np.array(train_loss),\n",
    "        \"train_accuracy\": np.array(train_accuracy),\n",
    "        \"test_loss\": np.array(test_loss),\n",
    "        \"test_accuracy\": np.array(test_accuracy)\n",
    "    }\n",
    "    return pd.DataFrame.from_dict(results)   \n",
    "\n",
    "def process_dataset(data_loader, methods, kernel_size_min, kernel_size_max, noise_level_min, noise_level_max):\n",
    "    \"\"\"Generate results over a single dataset\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader object): Dataloader object without heavy preprocessing steps\n",
    "        methods (List of Tuples): list of methods(functions) to be used on each datapoint of form (name, method, model)\n",
    "        kernel_size_min (int): For Gaussian Blur, minimum kernel size\n",
    "        kernel_size_max (int): For Gaussian Blur, maximum kernel size\n",
    "        noise_level_min (float): For adding noise, minimum noise level\n",
    "        noise_level_max (float): For adding noise, maximum noise level\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of results with keys as method names and values as torch tensors of results\n",
    "    \"\"\"\n",
    "    table = {}\n",
    "    # for i, (input_batch, input_labels) in enumerate(data_loader):\n",
    "    for i in range(0, TRUNCATE):\n",
    "        input_batch, input_labels = next(iter(data_loader))\n",
    "        input_batch.to(device)\n",
    "        input_labels = imagenette_to_imagenet_label_mapping_fast(input_labels).to(device)    \n",
    "        results = process_batch(\n",
    "            input_batch, \n",
    "            input_labels, \n",
    "            methods, \n",
    "            kernel_size_min, \n",
    "            kernel_size_max, \n",
    "            noise_level_min, \n",
    "            noise_level_max\n",
    "        )\n",
    "        for key, value in results.items():\n",
    "            # deal with empty tensors\n",
    "            if value == None:\n",
    "                    value = torch.empty(0)\n",
    "            # add to table\n",
    "            if key not in table.keys():\n",
    "                table[key] = value.detach()\n",
    "            else:\n",
    "                table[key] = torch.cat([table[key], value.detach()], dim = 0)\n",
    "        print(f\"Processed batch {i+1}/{len(data_loader)}\")\n",
    "    return table    \n",
    "\n",
    "def evaluate_explanations(train_data, test_data, save_results = False):\n",
    "    \"\"\"Evaluate the explanations of the model on the data\"\"\"\n",
    "    \n",
    "    # define params\n",
    "    kernel_size_min = 3\n",
    "    kernel_size_max = 5\n",
    "    noise_level_min = 0.1\n",
    "    noise_level_max = 0.2\n",
    "    # get the data\n",
    "    \n",
    "    # get the model\n",
    "    vgg16 = get_vgg16()\n",
    "    vgg19 = get_vgg19()\n",
    "    # define the methods\n",
    "    methods = [\n",
    "        (\"VGG16\", perform_lrp_plain, WrapperNet(vgg16, hybrid_loss=True)),\n",
    "        (\"VGG19\", perform_lrp_plain, WrapperNet(vgg19, hybrid_loss=True))\n",
    "    ]\n",
    "    train_table = process_dataset(train_data, methods, kernel_size_min, kernel_size_max, noise_level_min, noise_level_max)\n",
    "    test_table = process_dataset(test_data, methods, kernel_size_min, kernel_size_max, noise_level_min, noise_level_max)\n",
    "    # convert to pandas dataframe\n",
    "    df_train = pd.DataFrame(train_table)\n",
    "    df_test = pd.DataFrame(test_table)\n",
    "    \n",
    "    # save results\n",
    "    if save_results:\n",
    "        df_train.to_csv(\"train_results.csv\")\n",
    "        df_test.to_csv(\"test_results.csv\")\n",
    "    return df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_data, test_data = get_data_imagenette()\n",
    "vgg16_results = evaluate_performance(get_vgg16(), train_data, test_data)\n",
    "vgg19_results = evaluate_performance(get_vgg19(), train_data, test_data)\n",
    "\n",
    "# visualise results from the initial dataframes\n",
    "vgg16_results['model'] = 'VGG16'\n",
    "vgg19_results['model'] = 'VGG19'\n",
    "\n",
    "# Concatenate dataframes\n",
    "combined_df = pd.concat([vgg16_results, vgg19_results])\n",
    "\n",
    "# Melt the dataframe to long format for seaborn\n",
    "melted_df = combined_df.melt(id_vars=['model'], var_name='metric', value_name='value')\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='metric', y='value', hue='model', data=melted_df)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(title='Model')\n",
    "plt.show()\n",
    "\n",
    "# now evaluate explanations\n",
    "df_train, df_test = evaluate_explanations(train_data, test_data, save_results = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
